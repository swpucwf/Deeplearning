- 池化层
    - 最大池化
    - 平均池化
    - 降采样,一种添加先验的重要手段
    - 最大池化
        - 保留一些重要特征，一定程度上防止过拟合
        - 适合隐藏层
        - 平移不变性
    - 平均池化
        - 综合信息，常用输出层
- Dropout
    - 以固定概率随机丢弃一些神经元
    - 减少了神经元的依赖
    - 相当于生物进化

- BN层
    - 在批次上做归一化
    - 可以加更深的层数
    - 白化操作，去均值和方差
    - 添加了滑动参数,bias可以置False
    - 做到了归一化，改变了数据分布，允许每一层独立学习，加快了网络的收敛。 
    - 缺点：目前硬件没法做到批次很大，依赖训练集
- 输出层
    - 目前常用输出层
    - 全连接层
    - 平均池化层
        - 一定程度降维，减少参数量
        - 将特征提取与分类合二为一，一定程度防止过拟合
        - 实现任意尺度的输入
- 感受野
    - 特征图上某个点代表原来图像上的区域
    
    - 一般的实际感受野小于理论的感受野区
    
    - 计算公式
    
    - $$
      RF_{l+1} = RF_l+(k-1)*S_l
      $$
    
    - $S_l$为前面l层的步长之积，k代表l+l层卷积核的大小，$RF_l$上一层感受野
    
    - 卷积大小的输出计算
    
      - $$
        n_{out} = \frac{n_{in}+2p-k}{s} +1
        $$
    
      - p为padding,k为核大小，输入尺寸，s为步长